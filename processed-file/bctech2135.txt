Immigration Datawarehouse & AI-based recommendations Client Background Client: leading business school worldwide Industry Type: R&D Services: R&D, Innovation Organization Size: 100+ Project Objective Objective project research collect news article data sourcing Canada, based keyword. Project Description 3 phases project. Phase 1 – Data collection selection Data related coming (new comers) Data related coming (new comers) policy comers i.e. Data News, press, tanks, government policy documents, research institutions releasing news press news source limited Time span- 2005 2021 Output- Excel URLs documents source type, keywords, date article posted. Phase 2 – Documents text data extraction Develop tool collect extract data URL. Clean save texts text documents Phase 3 – Textual Analysis Sentiment Analysis Analysis readability Topic modelling Solution provide completed Phase 1 excel sheet ongoing Phase 2. work Phase 3 started complete Project way. Project Deliverables file excel sheet file summary dataset folders text files data Phase 2. Tools Python, PyCharm, Jupyter Notebook, Microsoft Excel, Google Chrome complete phases project Language/techniques Python programming language Web Scraping, Automation, Data Engineering project. Models SDLC process software project, software organization. consists detailed plan describing develop, maintain, replace alter enhance specific software. life cycle defines methodology improving quality software development process. Iterative Waterfall SDLC Model follow development software phases feedback step development project track occurring step. Figure 1 SDLC Iterative Waterfall Model Skills Data scraping, cleaning, pre-processing creating data pipelines project. Databases traditional storing data i.e file systems. technical Challenges Faced Project Execution lot challenges faced project execution. internet, raw data us. So, search important data specifically related only, lot keywords challenging part us. Then, manage task automating upto extent only, required find dates articles, news, tanks, documents etc, challenging part. working Phase 2, scrape data URLs, sometimes, news articles removed website, earlier datasets problems extracting data. cleaning webpages challenge us, project research, data important us. So, difficult data website require important. Technical Challenges Solved points solve technical challenges- sitemaps websites find articles require keywords, research find URL solve purpose. checking results automation tools, created, done. find dates articles, wrote multiple regular expressions, find match dates need, checking that. scrape removed webpages, WayBack machine google archives, stores deleted webpages. clean data, filtered HTML tags, classes, ids regex, research. Project Snapshots Previous article Lipsync Automation Celebrities Influencers article Leading Firm USA, SEO Website Optimization Ajay Bidyarthy RELATED ARTICLES AUTHOR Healthcare ChatBot LLAMA, LLM, Langchain Bot Audio audio Efficient Supply Chain Assessment: Overcoming Technical Hurdles Web Application Development